{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import Data\n",
    "This lab uses the [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset) from [Kaggle](https://www.kaggle.com).  \n",
    "\n",
    "In order to interact with the data in python, you will need to import the CSV into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53882</td>\n",
       "      <td>Male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10434</td>\n",
       "      <td>Female</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27419</td>\n",
       "      <td>Female</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>76.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60491</td>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>58.57</td>\n",
       "      <td>24.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "6  53882    Male  74.0             1              1          Yes   \n",
       "7  10434  Female  69.0             0              0           No   \n",
       "8  27419  Female  59.0             0              0          Yes   \n",
       "9  60491  Female  78.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "5        Private          Urban             186.21  29.0  formerly smoked   \n",
       "6        Private          Rural              70.09  27.4     never smoked   \n",
       "7        Private          Urban              94.39  22.8     never smoked   \n",
       "8        Private          Rural              76.15   NaN          Unknown   \n",
       "9        Private          Urban              58.57  24.2          Unknown   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "#Read in stroke data\n",
    "stroke_data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "#Display first 10 records of the data\n",
    "stroke_data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some summary statistics about the **stroke** column, which is what you will be trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,110 records in the stroke dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4861</td>\n",
       "      <td>0.951272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0        4861  0.951272\n",
       "1         249  0.048728"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the dataset\n",
    "total_records = stroke_data.shape[0]  # Get the number of rows in the DataFrame\n",
    "print('There are {:,} records in the stroke dataset.'.format(total_records)) \n",
    "\n",
    "# Create a summary DataFrame by grouping the data based on the 'stroke' column\n",
    "summary = pd.DataFrame(stroke_data.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "# Calculate the percentage of each group by dividing the count of each group by the total number of records\n",
    "summary['Percent'] = summary['Count'] / total_records\n",
    "summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of techniques to deal with [unbalanced datasets](https://medium.com/strands-tech-corner/unbalanced-datasets-what-to-do-144e0552d9cd).  \n",
    "\n",
    "We will use the **true positive rate** to assess the performance of your predictions.\n",
    "<center>\n",
    "    $\\text{True Positive Rate} = \\frac{TP}{TP+FN}$\n",
    "</center>  \n",
    "\n",
    "where \n",
    "* $TP$ is the number of true positive predictions (actual value = stroke; predicted value = stroke)\n",
    "* $FN$ is the number of false negative predictions (actual value = stroke; predicted value = no stroke)\n",
    "\n",
    "This value, also called [sensitivity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) or [recall](https://en.wikipedia.org/wiki/Precision_and_recall), measures how well a model is at capturing actual stroke cases.  \n",
    "\n",
    "Assuming medical interventions are relatively cheap (i.e., recommending weight loss or exercise to a patient in danger of a stroke), it is better to have the occasional false positive than miss patients at high risk for strokes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build a model that identifies factors indicating a high likelihood of having a stroke, so interventions can hopefully prevent the stroke *before* it happens.  \n",
    "\n",
    "This being the case, we need to evaluate correct predictions on data that the model has never seen before.  This can be done by splitting our data into a training dataset (to use for training and evaluating the model as it is being built) and a test dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup\n",
    "Categorical variables that will be used to predict strokes need to be converted to [dummy variables](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)).  \n",
    "\n",
    "We also need to replace missing data in the BMI column.  \n",
    "I will simply use the average BMI to replace the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender\n",
    "#First, to make things easier, remove the one \"other\" gender value.\n",
    "stroke_data = stroke_data[stroke_data['gender'] != 'Other']\n",
    "#Add new column 'male': 1 = male; 0 = female\n",
    "stroke_data['male'] = pd.get_dummies(stroke_data['gender'], drop_first=True)\n",
    "\n",
    "#Residence Type\n",
    "#Add new column 'urban': 1 = urban; 0 = rural\n",
    "stroke_data['urban'] = pd.get_dummies(stroke_data['Residence_type'], drop_first=True)\n",
    "\n",
    "#Married\n",
    "stroke_data['married'] = pd.get_dummies(stroke_data['ever_married'], drop_first=True)\n",
    "\n",
    "#Smoking Status\n",
    "smoking_dummies = pd.get_dummies(stroke_data['smoking_status'], drop_first=True)\n",
    "stroke_data = pd.concat([stroke_data, smoking_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Missing BMI with average BMI\n",
    "bmi_average = stroke_data['bmi'].mean()\n",
    "stroke_data['bmi'] = stroke_data['bmi'].fillna(bmi_average)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Create a Test Dataset\n",
    "Now, let's split your dataset into two datasets:\n",
    "* Training Data: Used to train your model to identify important predictors of stroke\n",
    "* Test Data: Reserved to evaluate the model on new, unseen data\n",
    "\n",
    "We will use the [scikit-learn](https://scikit-learn.org/stable/index.html) package in python, since has many tools for machine learning, including data preparation tools. \n",
    "\n",
    "Let's take a look on the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.  \n",
    "\n",
    "Inputs to *train_test_split*:\n",
    " * **arrays**: This is where you enter one or more arrays: the entire dataset including the output or two separate arrays (X array (predictors) and y array (output) variable).  If you enter two arrays, the number of rows in the X and y arrays must be the same and the indexes must align the data.\n",
    " * **test_size**: Value between 0 and 1 that indicates the percentage of data to be reserved for the test dataset (defaults to 0.25 if train_size is None).\n",
    " * **train_size**: Value between 0 and 1 that indicates the percentage of data to be used for the training dataset (complement of test_size if test_size is set and this value is None).\n",
    " * **random_state**: Seed value for randomizing the data split.\n",
    " * **shuffle**: Whether to shuffle the data before splitting (defaults to True).\n",
    " * **stratify**: Output field to use for [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling)  (defaults to None).\n",
    " \n",
    "Since our dataset has unbalanced output classes, you want to be sure to use the **stratify** option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train_test_split function from scikit-learn package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(stroke_data,train_size=0.8,stratify=stroke_data['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4,087 records in the training dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3888</td>\n",
       "      <td>0.951309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>0.048691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0        3888  0.951309\n",
       "1         199  0.048691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the training dataset\n",
    "training_records = train.shape[0]\n",
    "print('There are {:,} records in the training dataset.'.format(training_records))\n",
    "\n",
    "train_summary = pd.DataFrame(train.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "train_summary['Percent'] = train_summary['Count'] / training_records\n",
    "train_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,022 records in the test dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>972</td>\n",
       "      <td>0.951076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.048924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count   Percent\n",
       "stroke                 \n",
       "0         972  0.951076\n",
       "1          50  0.048924"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the total records in the test dataset\n",
    "test_records = test.shape[0]\n",
    "print('There are {:,} records in the test dataset.'.format(test_records))\n",
    "\n",
    "test_summary = pd.DataFrame(test.groupby('stroke').size()).rename(columns={0:'Count'})\n",
    "test_summary['Percent'] = test_summary['Count'] / test_records\n",
    "test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80.0% of all records in training dataset.\n"
     ]
    }
   ],
   "source": [
    "#Confirm the split did what you expected!\n",
    "print('There are {:.1%} of all records in training dataset.'.format(training_records/total_records))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Tune Models Using Validation Data\n",
    "By creating a validation data dataset, I want to be sure that this is the best algorithm and best settings for your dataset.  \n",
    "This is *another* split of the data, this time using the training dataset.\n",
    "\n",
    "Using the training dataset, you can again use the *train_test_split* function to create two new datasets:\n",
    " * train_final: The final dataset used to train your models\n",
    " * validation: The dataset used to evaluate and tune your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data into training/validation data using a 75%/25% split\n",
    "#Be sure to use stratified sampling!\n",
    "train_final, validation = train_test_split(train, train_size=0.75, stratify=train['stroke'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally built a binary classification model to predict strokes.  \n",
    "\n",
    "You will be using the [K-Nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) to build your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the training dataset is 15.436%.\n"
     ]
    }
   ],
   "source": [
    "#Import KNN model function from scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Remove 'id' and 'stroke' column from features (predictors)\n",
    "features = ~train_final.columns.isin(['id','gender','ever_married','work_type','Residence_type','smoking_status','stroke'])\n",
    "feature_columns = train_final.columns[features]\n",
    "model.fit(train_final[feature_columns],train_final['stroke'])\n",
    "\n",
    "\n",
    "#Import true positive rate (recall) function\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Predict output for training dataset\n",
    "train_predict = model.predict(train_final[feature_columns])\n",
    "\n",
    "tpr_train = recall_score(train_final['stroke'],train_predict)\n",
    "print('The true positive rate for the training dataset is {:.3%}.'.format(tpr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the validation dataset is 0.000%.\n"
     ]
    }
   ],
   "source": [
    "#Predict output for validation dataset\n",
    "validation_predict = model.predict(validation[feature_columns])\n",
    "\n",
    "tpr_validation = recall_score(validation['stroke'],validation_predict)\n",
    "print('The true positive rate for the validation dataset is {:.3%}.'.format(tpr_validation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs significantly worse in predicting strokes for the validation dataset than on the training dataset.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "Instead of using a single static validation dataset, you can try cross-validation.  [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) splits the training dataset into *k* folds, and then creates a temporary training dataset consisting of *k-1* folds to build a model.  The process is repeated *k* times, holding a different fold of the training data out each time.  Then the validation metric is averaged across all *k* models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 5, 10, 15, 100],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [1, 2, 5, 10, 15, 100],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 5, 10, 15, 100],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#KNN parameters to test\n",
    "parameters = {'n_neighbors': [1,2,5,10,15,100], 'weights': ['uniform','distance']}\n",
    "\n",
    "#Initialize model\n",
    "knn = KNeighborsClassifier()\n",
    "#Set up a grid search for the best hyperparameters using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn, parameters, cv=5, scoring='recall')\n",
    "#Fit model using the full training\n",
    "grid_search.fit(train[feature_columns],train['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CV true positive rate from the grid search was 15.590%.\n"
     ]
    }
   ],
   "source": [
    "#Show the best true positive rate results of the grid search\n",
    "print('The best CV true positive rate from the grid search was {:.3%}.'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the best model parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Evaluate the Best Model on Unseen Data\n",
    "Finally, you can see how well \"best\" model predicts strokes for the test dataset.  This is how we simulate how well the model will do in the real-world against totally new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the training dataset is 100.0%.\n"
     ]
    }
   ],
   "source": [
    "#Build your \"best\" model using the best parameters from the grid search\n",
    "knn_best = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "knn_best.fit(train[feature_columns],train['stroke'])\n",
    "\n",
    "#Calculate training true positive rate\n",
    "training_predict = knn_best.predict(train[feature_columns])\n",
    "training_tpr = recall_score(train['stroke'], training_predict)\n",
    "\n",
    "print('The true positive rate for the training dataset is {:.1%}.'.format(training_tpr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model performs perfectly on the training dataset!  Whenever you see a perfect training score, you should be skeptical.  It is very likely that you are dealing with [overfitting](https://en.wikipedia.org/wiki/Overfitting), where the model learned the training dataset TOO well.  This generally means that the model will not generalize well when compared to real world data.\n",
    "\n",
    "So now you can use this same model to predict strokes using the test dataset and see how the true positive rate compares to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true positive rate for the test dataset is 16.0%.\n"
     ]
    }
   ],
   "source": [
    "#Calculate test true positive rate\n",
    "test_predict = knn_best.predict(test[feature_columns])\n",
    "test_tpr = recall_score(test['stroke'], test_predict)\n",
    "\n",
    "print('The true positive rate for the test dataset is {:.1%}.'.format(test_tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
